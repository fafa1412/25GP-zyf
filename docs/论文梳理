---

### **CAT框架实现异步函数跟踪的依赖组件及协作流程**

---

#### **1. 核心组件与功能**
| **组件**                | **功能描述**                                                                 | **技术实现细节**                                                                 |
|-------------------------|-----------------------------------------------------------------------------|---------------------------------------------------------------------------------|
| **动态二进制插桩工具**   | 在目标程序的特定函数入口/出口插入探针，记录异步任务生命周期事件。              | 使用`uftrace`工具，依赖Linux的`perf_event`接口，支持动态插桩（运行时NOP指令替换）。 |
| **上下文分类模型**       | 定义异步任务的执行上下文类型（任务、编译器生成、用户实现、匿名）。             | 基于Rust标准库和运行时API分析（如`task::spawn`、`async/await`生成的Future对象）。 |
| **数据收集模块**         | 捕获时间戳、线程ID、函数名、上下文类型、栈深度等原始数据。                     | 探针生成日志条目，缓冲至RAM磁盘避免I/O阻塞，支持跨线程异步写入。                  |
| **栈回溯与数据处理**     | 解析嵌套异步任务的执行顺序和层级关系，计算任务执行时间。                       | 通过栈推入/弹出操作关联入口和退出事件，生成任务时间区间（`entry_ts - exit_ts`）。 |
| **跨运行时适配层**       | 支持不同Rust运行时（如`async-std`、`tokio`）的异步任务追踪。                   | 分析各运行时的任务调度API（如`tokio::spawn`），统一映射到上下文分类模型。         |
| **可视化工具链**         | 将结构化数据转换为时间线图，展示任务调度、阻塞事件和性能瓶颈。                 | 使用`Trace-viewer`解析JSON格式日志，生成交互式时间线图。                          |

---

#### **2. 协作流程**
1. **插桩阶段**  
   - **输入**：目标Rust程序（需编译为调试模式）。  
   - **操作**：通过`uftrace`在以下位置插入探针：  
     - 任务创建点（如`task::spawn`）。  
     - `async/await`语法生成的Future入口/出口。  
     - 用户自定义Future的`poll`方法。  
   - **输出**：插桩后的二进制文件，包含动态探针。  

2. **数据收集阶段**  
   - **运行时行为**：程序执行时，探针记录：  
     - 任务启动/结束时间戳、线程ID。  
     - 嵌套Future的层级关系（通过栈深度标识）。  
   - **数据缓冲**：日志写入RAM磁盘，后台异步持久化，避免阻塞程序执行。  

3. **数据处理阶段**  
   - **栈回溯解析**：根据入口/退出事件重建任务执行流，例如：  
     ```plaintext  
     [entry] Task A (Depth=1) @ T=100ms  
     [entry] Future B (Depth=2) @ T=105ms  
     [exit]  Future B (Depth=2) @ T=120ms → 执行时间=15ms  
     [exit]  Task A (Depth=1) @ T=150ms → 总时间=50ms  
     ```  
   - **结构化输出**：转换为包含任务ID、父任务、耗时、上下文类型的JSON数据。  

4. **可视化阶段**  
   - **时间线生成**：`Trace-viewer`将JSON数据渲染为：  
     - 水平条表示任务持续时间。  
     - 垂直层级展示嵌套关系（如`Task A → Future B`）。  
     - 颜色标记阻塞事件（红色）或I/O操作（蓝色）。  
   - **交互分析**：用户可缩放时间线、查看任务元数据、筛选特定上下文类型。  

---

---

#### **1. 插桩阶段**
- **对应文件**：`profile.sh`
- **代码片段**：
  ```bash
  if [ "$3" = "async_std" ]; then
      uftrace record -P "_<async_std..task..builder..SupportTaskLocals<F> as core..future..future..Future>::poll::_{{closure}}" ... $1
  elif [ "$3" = "tokio" ]; then
      uftrace record -P "tokio..runtime..blocking..task..BlockingTask<T> as core..future..future..Future" ... $1
  fi
  ```
- **功能**：
  - 根据指定的运行时（`async_std` 或 `tokio`），调用 `uftrace` 动态插桩工具。
  - 通过正则表达式（`-P` 参数）匹配目标函数（如任务创建点、`poll` 方法入口/出口）。
  - 生成插桩后的二进制文件并运行，记录跟踪数据到 `.dat` 文件。

---

#### **2. 数据收集阶段**
- **对应文件**：`profile.sh`
- **代码片段**：
  ```bash
  uftrace dump > dumped_data.txt
  mv ./dumped_data.txt ./profile/
  ```
- **功能**：
  - 将 `uftrace` 记录的二进制跟踪数据（`.dat` 文件）转换为文本格式 `dumped_data.txt`。
  - 文本数据包含函数调用事件（如 `entry` 和 `exit`）、时间戳、线程ID、栈深度等原始信息。

---

#### **3. 数据处理阶段**
- **对应文件**：`parser.py`
- **代码片段**：
  ```python
  for line in fp:
      if re.search("reading (.*).dat", line):
          thread_list.append(threads[0])  
      # 状态机逻辑解析每行数据...
  
  def output_in_json(...):
      # 构建 trace_events 列表并生成 JSON
  ```
- **功能**：
  - **状态机解析**：通过正则表达式和状态变量（`find_task_state`）解析 `dumped_data.txt`，识别异步任务的创建、嵌套 Future 的 `poll` 调用等事件。
  - **数据转换**：将原始事件转换为 `Trace-viewer` 兼容的 JSON 格式，包括：
    - **时间戳转换**：将秒级时间戳转换为微秒级。
    - **符号修饰**：清理函数名（如替换 `..` 为 `::`）。
    - **上下文关联**：通过栈深度和线程ID重建任务层级。
  - **可选功能**：通过 `--get-location` 参数获取函数在源码中的位置（调用 `objdump` 反汇编）。

---

#### **4. 可视化阶段**
- **对应文件**：`parser.py` 生成的 JSON 文件
- **代码片段**：
  ```python
  data = {"traceEvents": trace_events, "displayTimeUnit": "ms"} 
  jsonfile.write(json.dumps(data))
  ```
- **功能**：
  - 生成符合 `Trace-viewer` 格式的 JSON 文件，包含每个异步事件的开始（`"ph": "B"`）和结束（`"ph": "E"`）标记。
  - 用户通过浏览器打开 `Trace-viewer`（如 `chrome://tracing`）加载 JSON 文件，查看时间线图：
    - **水平条**：表示任务的执行时间。
    - **嵌套层级**：通过垂直位置展示任务和 Future 的父子关系。
    - **颜色标记**：区分不同事件类型（如阻塞、I/O）。

---

### **总结**
- **`profile.sh` 负责**：  
  - 插桩（调用 `uftrace`）、数据收集（生成 `dumped_data.txt`）、调用解析脚本。
- **`parser.py` 负责**：  
  - 数据处理（解析原始日志、重建任务流）、生成可视化所需的 JSON 文件。
- **协作流程**：  
  1. `profile.sh` 插桩并运行程序，生成原始数据。  
  2. `parser.py` 解析数据，生成 JSON。  
  3. 用户通过 `Trace-viewer` 查看时间线图。  
